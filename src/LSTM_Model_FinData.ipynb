{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3031c029",
   "metadata": {},
   "source": [
    "# Creating an LSTM Model for Buy/Sell signal prediction on stock price data\n",
    "## Contents\n",
    "1. Download stock price data for all S&P 500 stocks\n",
    "2. Clean up data\n",
    "3. Preprocess data for LSTM Model\n",
    "4. Train Model\n",
    "5. Test Model\n",
    "6. Evaluate Model based on backtest with real price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44569c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bccfe7",
   "metadata": {},
   "source": [
    "## Download stock price data for all S&P 500 stocks\n",
    "\n",
    "We download the ticker data for about 30000 ticker symbols from yahoo finance.\n",
    "For this we use a csv file containing valid tickers with financial data from https://github.com/ahnazary/Finance/blob/master/finance/src/database/valid_tickers.csv.\n",
    "\n",
    "We use these tickers as a base for our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import yfinance as yf\n",
    "import logging\n",
    "from dask.delayed import delayed\n",
    "from dask.base import compute\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "\n",
    "    # download data for a single ticker symbol\n",
    "    @delayed\n",
    "    def download_ticker_data(ticker):\n",
    "        try:\n",
    "            df = yf.download(ticker, start=\"2015-01-01\", end=\"2024-01-01\", progress=False)\n",
    "            if df is None or df.empty:\n",
    "                logging.warning(f\"No data found for {ticker}\")\n",
    "                return None\n",
    "            logging.info(f\"Downloaded data for {ticker}\")\n",
    "            df = df.reset_index()\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "            df = df.set_index(\"Date\")\n",
    "            df[\"Symbol\"] = ticker\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "    # download data for ticker symbols in batches to avoid hitting thread limits\n",
    "    def run_batches(tickers, batch_size = 500):\n",
    "        all_batches = []\n",
    "        for i in range(0, len(tickers), batch_size):\n",
    "            batch = tickers[i : i + batch_size]\n",
    "            delayed_data = [download_ticker_data(t) for t in batch]\n",
    "            logging.info(f\"Number of tickers in queue: {len(delayed_data)}\")\n",
    "            results = compute(*delayed_data, scheduler = \"threads\")\n",
    "            valid_results = [\n",
    "                dd.from_pandas(r, npartitions=1)\n",
    "                for r in results\n",
    "                if r is not None and isinstance(r, dd.DataFrame)\n",
    "            ]\n",
    "            valid_results = [\n",
    "                dd.from_pandas(r, npartitions=1)\n",
    "                for r in valid_results\n",
    "                if r.npartitions > 0\n",
    "            ]\n",
    "            if valid_results:\n",
    "                batch_df = dd.concat(valid_results)\n",
    "                all_batches.append(batch_df)\n",
    "            logging.info(f\"Batch {i // batch_size + 1} completed.\")\n",
    "        if all_batches == []:\n",
    "            logging.error(\"No valid data found in any batch.\")\n",
    "            return None\n",
    "        return dd.concat(all_batches)\n",
    "\n",
    "    # Read ticker data from CSV\n",
    "    filepath = \"../data/ticker_Symbols_yfinance.csv\"\n",
    "    tickers = dd.read_csv(\n",
    "        filepath,\n",
    "        dtype={\n",
    "            \"market_cap\": \"float64\",\n",
    "            \"total_assets\": \"float64\",\n",
    "            \"total_revenue\": \"float64\",\n",
    "        },\n",
    "    )\n",
    "    tickers = tickers[\"ticker\"].compute().tolist()\n",
    "    tickers = list(set(tickers))\n",
    "    logging.info(f\"Number of tickers: {len(tickers)}\")\n",
    "\n",
    "\n",
    "    # Check if tickers list is not empty\n",
    "    if not tickers:\n",
    "        logging.error(\"Ticker list is empty. Please check the input file.\")\n",
    "    else:\n",
    "        # Download data for each ticker in parallel using delayed\n",
    "        stock_data = run_batches(tickers, batch_size=500)\n",
    "\n",
    "        if stock_data is not None and stock_data.npartitions > 0:\n",
    "            stock_data = stock_data.sort_values([\"Symbol\", \"Date\"])\n",
    "            logging.info(\"All tickers downloaded.\")\n",
    "            logging.info(f\"stock_data.npartitions: {stock_data.npartitions}\")\n",
    "            \n",
    "            stock_data = stock_data.sort_values([\"ticker\", \"Date\"])\n",
    "            stock_data.to_csv(\"../data/stock_data.csv\", index = False, single_file=True)\n",
    "            logging.info(\"Data saved to CSV file.\")\n",
    "            return stock_data\n",
    "        else:\n",
    "            logging.error(\"Dask DataFrame is empty or not properly formed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d981aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 18:35:16,170 - INFO - Data already available, skipping download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Symbol  Adj Close      Close       High        Low       Open  \\\n",
      "0 2018-01-02      A  64.625580  67.599998  67.889999  67.339996  67.419998   \n",
      "1 2018-01-03      A  66.269882  69.320000  69.489998  67.599998  67.620003   \n",
      "2 2018-01-04      A  65.772766  68.800003  69.820000  68.779999  69.540001   \n",
      "3 2018-01-05      A  66.824364  69.900002  70.099998  68.730003  68.730003   \n",
      "4 2018-01-08      A  66.967758  70.050003  70.330002  69.550003  69.730003   \n",
      "\n",
      "      Volume  \n",
      "0  1047800.0  \n",
      "1  1698900.0  \n",
      "2  2230700.0  \n",
      "3  1632500.0  \n",
      "4  1613400.0  \n"
     ]
    }
   ],
   "source": [
    "filepath = \"../data/sp500_stocks.csv\"\n",
    "\n",
    "# check if file is already available\n",
    "try:\n",
    "    stock_data = dd.read_csv(filepath)\n",
    "    stock_data[\"Date\"] = stock_data[\"Date\"].map_partitions(dd.to_datetime, errors='coerce')\n",
    "    stock_data.set_index(\"Date\", inplace=True)\n",
    "    stock_data.sort_values(by=[\"Symbol\", \"Date\"], inplace=True)\n",
    "    stock_data = stock_data.compute()\n",
    "    print(stock_data.head())\n",
    "    logging.info(\"Data already available, skipping download.\")\n",
    "except FileNotFoundError:\n",
    "    stock_data = download_data()\n",
    "    if stock_data is not None:\n",
    "        print(stock_data.head())\n",
    "    logging.info(\"Data not available, please download it first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 18:28:19,802 - ERROR - No valid delayed results to process.\n"
     ]
    }
   ],
   "source": [
    "# add technical indicators to each stock symbol\n",
    "# for added indicators, see ta.add_all_ta_features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TradingStrategies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
